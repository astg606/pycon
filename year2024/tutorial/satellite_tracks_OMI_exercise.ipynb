{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-24vit7OoB1x"
   },
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h2><font color= \"blue\" size=\"+3\">PyCon 2024 Tutorial</font></h2>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h3>Python Workflows to Extract and Plot Satellite Data Products along Tracks</h3>\n",
    "    <h2><font color=\"red\" size=\"+3\">Aura Satellite - Option 3</font></h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqZRoZwmoB11"
   },
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\"> Objectives</font>\n",
    "\n",
    "Use a collection of OMI data files to:\n",
    "- Gather timeseries data (time, location, value) of surface pressure\n",
    "- Plot the data on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLTjzNBJoB12"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nT_3Q7CUoB15"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZX-VYGqaoB16"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBT2ouX8oB16"
   },
   "outputs": [],
   "source": [
    "from shapely import geometry as shpgeom\n",
    "from shapely import wkt as shpwkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import movingpandas as mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_defaults = {'linewidth':5, 'capstyle':'round', 'figsize':(9,3), 'legend':True}\n",
    "hv.opts.defaults(hv.opts.Overlay(active_tools=['wheel_zoom'], \n",
    "                              frame_width=500, frame_height=400))\n",
    "hvplot_defaults = {'tiles':None, 'cmap':'Viridis', 'colorbar':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Files\n",
    "\n",
    "- The [TROPESS OMI-Aura L2 Ozone for Forward Stream](https://disc.gsfc.nasa.gov/datasets/TRPSDL2O3OMIFS_1/summary?keywords=AURA), Standard Product contains the vertical distribution of the retrieved atmospheric state of ozone (O3), formal uncertainties, and diagnostic information measured by the OMI instrument on the EOS Aura satellite.\n",
    "- The forward stream standard product is global for the time period from 2021-02-01 to present. \n",
    "- The data files are written in the netCDF version 4 file format, and each file contains one day of data.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/jkouatch/myTasks/PythonTraining/ASTG606/Materials/sat_data/OMI_Data/\"\n",
    "#data_dir = \"/tljh-data/sat_data/OMI_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files =[\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t0007-o104295_v003-2024m0223t055537.he5\",\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t0146-o104296_v003-2024m0223t072107.he5\",\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t0325-o104297_v003-2024m0223t092257.he5\",\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t0503-o104298_v003-2024m0223t110728.he5\",\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t0642-o104299_v003-2024m0223t142711.he5\",\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t0821-o104300_v003-2024m0223t160655.he5\",\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t1000-o104301_v003-2024m0223t161921.he5\",\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t1139-o104302_v003-2024m0223t174944.he5\",\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t1318-o104303_v003-2024m0223t190943.he5\",\n",
    "    \"OMI-Aura_L2-OMAERO_2024m0223t1456-o104304_v003-2024m0223t224147.he5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: <font color=\"green\"> Understand the structure of one data file</green>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = Path(data_dir) / list_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_attrs(name, obj):\n",
    "    shift = name.count('/') * '    '\n",
    "    print(shift + name)\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        print(shift + '    ' + f\"Shape: {obj[()].shape}\")\n",
    "    for key, val in obj.attrs.items():\n",
    "        print(shift + '    ' + f\"{key}: {val}\")\n",
    "        \n",
    "with h5py.File(fname, mode='r') as fid:\n",
    "    fid.visititems(print_attrs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please identify the datasets:\n",
    "\n",
    "- `Time`\n",
    "- `SpacecraftLatitude`\n",
    "- `SpacecraftLongitude`\n",
    "- `SingleScatteringAlbedoMW`\n",
    "- `CloudPressure`\n",
    "\n",
    "Please pay attention to the attributes of `SingleScatteringAlbedoMW` and `CloudPressure`, and the multi-wavelengths of `SingleScatteringAlbedoMW` (we will only use the first one here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: <font color=\"green\">Write a simple code to get the `Time`, `SpacecraftLatitude`, `SpacecraftLongitude`, `SingleScatteringAlbedoMW` and `CloudPressure` data arrays from one file</font>\n",
    "\n",
    "Write a function that takes as argument a file name and a grpund pixel identifier, and returns values for the SingleScatteringAlbedoMW (first wavelength), CloudPressure, the time, the lalitude and the longitude:\n",
    "\n",
    "```python\n",
    "\n",
    "cloud_name = 'CloudPressure'\n",
    "alb_name = 'SingleScatteringAlbedoMW'\n",
    "\n",
    "def get_arrays(fname, ipxl):\n",
    "    with h5py.File(fname, 'r') as fid:\n",
    "        ...\n",
    "    return scatt_alb, cloud_press, time, lats, lons\n",
    "   ...\n",
    "```\n",
    "Test the funtion using any of the above file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_name = 'CloudPressure'\n",
    "alb_name = 'SingleScatteringAlbedoMW'\n",
    "\n",
    "def get_arrays(fname, ipxl):\n",
    "    with h5py.File(fname, 'r') as h5f:\n",
    "        geol_group = h5f['HDFEOS/SWATHS/ColumnAmountAerosol/Geolocation Fields']\n",
    "        data_group = h5f['HDFEOS/SWATHS/ColumnAmountAerosol/Data Fields']\n",
    "        scatt_alb = data_group[alb_name][:,:,ipxl]\n",
    "        cloud_pres = data_group[cloud_name][()]\n",
    "        time = geol_group['Time'][()]\n",
    "        lats = geol_group['Latitude'][()][:,ipxl]\n",
    "        lons = geol_group['Longitude'][()][:,ipxl]\n",
    "    return scatt_alb, cloud_pres, time, lats, lons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"purple\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "cloud_name = 'CloudPressure'\n",
    "alb_name = 'SingleScatteringAlbedoMW'\n",
    "\n",
    "def get_arrays(fname):\n",
    "    with h5py.File(fname, 'r') as h5f:\n",
    "        geol_group = h5f['HDFEOS/SWATHS/ColumnAmountAerosol/Geolocation Fields']\n",
    "        data_group = h5f['HDFEOS/SWATHS/ColumnAmountAerosol/Data Fields']\n",
    "        scatt_alb = data_group[alb_name][:,:,0]\n",
    "        cloud_press = data_group[cloud_name][()]\n",
    "        time = geol_group['Time'][()]\n",
    "        lats = geol_group['SpacecraftLatitude'][()]\n",
    "        lons = geol_group['SpacecraftLongitude'][()]\n",
    "    return scatt_alb, cloud_press, time, lats, lons\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test your function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipxl = 0\n",
    "AL, CP, T,LA, LO = get_arrays(fname, ipxl)\n",
    "\n",
    "print(f\"Shape of {alb_name}: {AL.shape}\")\n",
    "print(f\"Shape of {cloud_name}: {CP.shape}\")\n",
    "print(f\"Shape of time:      {T.shape}\")\n",
    "print(f\"Shape of latitude:  {LA.shape}\")\n",
    "print(f\"Shape of longitude: {LO.shape}\")\n",
    "\n",
    "AL, CP, T, LA, LO = None, None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: <font color=\"green\">Read the data files</font>\n",
    "\n",
    "To write a script that loops over the data files and reads each of them to:\n",
    "- Gather the time, latitude, longitude, cloud presssure and scattering albedo (first bin only)\n",
    "   - For cloud presssure and scattering albedo only take the first...\n",
    "- Use the cloud presssure and scattering albedo attributes to restore the values\n",
    "- Load the data in a Pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_dtype(sample_dict):\n",
    "    '''\n",
    "    Converts attribute dictionary from NumPy data types \n",
    "    to general Python data types\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_dict : dict\n",
    "         A dictionary of attributes\n",
    "         \n",
    "    Returns\n",
    "    sample_dict : dictt\n",
    "         A dictionary of attributes\n",
    "    '''\n",
    "    for key, item in sample_dict.items():\n",
    "        if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "            item = list(item)\n",
    "        \n",
    "            if len(item) == 1:\n",
    "                item = item[0]\n",
    "        elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "            item = str(item.astype('str'))\n",
    "        \n",
    "            if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "                item = eval(item)\n",
    "            # **eval() relaiability??**\n",
    "            \n",
    "        sample_dict[key] = item   # Updates any changes to the key value\n",
    "        \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_attrs(ds):\n",
    "    \"\"\"\n",
    "       Give a dataset identifier, return the dataset attribute.\n",
    "       \n",
    "       Input Parameters:\n",
    "          - ds: dataset identifier\n",
    "       Returned value:\n",
    "          - ds_attrs: a dictionary\n",
    "    \"\"\"\n",
    "    ds_attrs = dict(ds.attrs)\n",
    "    ds_attrs = convert_dict_dtype(ds_attrs)\n",
    "    \n",
    "    return ds_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_attribute_value(ds_attrs, attr_name):\n",
    "    '''\n",
    "    Obtain the value of a specified attribute in a dataset.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    ds_attrs : dict\n",
    "         A dictionary of dataset attributes\n",
    "    attr_name : str\n",
    "         Attribute name    \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    value: float, int, str, list\n",
    "         Value of the attribute. If attribute not available, None.\n",
    "    '''\n",
    "    for key, value in ds_attrs.items():\n",
    "        if key == attr_name:\n",
    "            return value \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(ds):\n",
    "    '''\n",
    "    Restore the dataset data using the dataset attributes.\n",
    "      \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : h5py dataset identifier\n",
    "    \n",
    "    Returns:\n",
    "    data : numpy array\n",
    "    '''\n",
    "    ds_attrs = get_ds_attrs(ds)\n",
    "    \n",
    "    fill_value = get_ds_attribute_value(ds_attrs, '_FillValue')\n",
    "    missing_value = get_ds_attribute_value(ds_attrs, 'MissingValue')\n",
    "    scale_factor = get_ds_attribute_value(ds_attrs, 'scale_factor')\n",
    "    add_offset = get_ds_attribute_value(ds_attrs, 'add_offset')\n",
    "    \n",
    "    data = ds[()]#.astype('float')\n",
    "\n",
    "    data = np.where(data != missing_value, data, np.nan)\n",
    "    data = np.where(data != fill_value, data, np.nan)\n",
    "    if add_offset:\n",
    "        data -= add_offset\n",
    "    if scale_factor:\n",
    "        data *= scale_factor\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note that the surface temperature has a `missing_value` and a `_FillValue` attributes. We need to make sure that any entry with that value needs to be replaced with `NaN`.__\n",
    "\n",
    "<font color=\"green\">Rewrite the function in Step 2 to restore the surface temperature data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"purple\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "def get_arrays(fname, ipxl):\n",
    "    with h5py.File(fname, 'r') as h5f:\n",
    "        geol_group = h5f['HDFEOS/SWATHS/ColumnAmountAerosol/Geolocation Fields']\n",
    "        data_group = h5f['HDFEOS/SWATHS/ColumnAmountAerosol/Data Fields']\n",
    "        scatt_alb = restore_data(data_group[alb_name])[:,0,ipxl]\n",
    "        cloud_pres = restore_data(data_group[cloud_name])[:,ipxl]\n",
    "        time = geol_group['Time'][()]\n",
    "        lats = geol_group['SpacecraftLatitude'][()][:,ipxl]\n",
    "        lons = geol_group['SpacecraftLongitude'][()][:,ipxl]\n",
    "    return scatt_alb, cloud_pres, time, lats, lons\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipxl = 0\n",
    "AL, CP, T,LA, LO = get_arrays(fname, ipxl)\n",
    "\n",
    "print(f\"Shape of {alb_name}: {AL.shape}\")\n",
    "print(f\"Shape of {cloud_name}: {CP.shape}\")\n",
    "print(f\"Shape of time:      {T.shape}\")\n",
    "print(f\"Shape of latitude:  {LA.shape}\")\n",
    "print(f\"Shape of longitude: {LO.shape}\")\n",
    "\n",
    "AL, CP, T, LA, LO = None, None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Write your script here:\n",
    "\n",
    "```python\n",
    "first_iter = True\n",
    "for i in range(len(list_files)):\n",
    "    fname = Path(data_dir) / list_files[i]\n",
    "    print(f\"Reading: {fname}\")\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = len(list_files)\n",
    "ipxl = 0\n",
    "first_iter = True\n",
    "for i in range(num_files):\n",
    "    fname = Path(data_dir) / list_files[i]\n",
    "    print(f\"Reading: {fname}\")\n",
    "    AL, CP, T,LA, LO = get_arrays(fname, ipxl)\n",
    "    traj = np.full_like(T, i+1, dtype=int) # Index to distinguish files.\n",
    "    if first_iter:\n",
    "        first_iter = False\n",
    "        scatt_alb, cloud_pres, time, lats, lons = AL, CP, T, LA, LO\n",
    "        traj_id = traj\n",
    "    else:\n",
    "        scatt_alb = np.concatenate((scatt_alb, AL), axis=0)\n",
    "        cloud_pres = np.concatenate((cloud_pres, CP), axis=0)\n",
    "        time = np.concatenate((time, T), axis=0)\n",
    "        lats = np.concatenate((lats, LA), axis=0)\n",
    "        lons = np.concatenate((lons, LO), axis=0)\n",
    "        traj_id = np.concatenate((traj_id, traj), axis=0)\n",
    "        \n",
    "AL, CP, T, LA, LO, traj = None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"purple\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "num_files = len(list_files)\n",
    "first_iter = True\n",
    "for i in range(1):\n",
    "    fname = Path(data_dir) / list_files[i]\n",
    "    print(f\"Reading: {fname}\")\n",
    "    X, Y, Z, W = get_arrays(fname)\n",
    "    if first_iter:\n",
    "        first_iter = False\n",
    "        surf_temp, time, lats, lons = X, Y, Z, W\n",
    "    else:\n",
    "        surf_temp = np.concatenate((surf_temp, X), axis=0)\n",
    "        time = np.concatenate((time, Y), axis=0)\n",
    "        lats = np.concatenate((lats, Z), axis=0)\n",
    "        lons = np.concatenate((lons, W), axis=0)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: <font color=\"green\">Create the Pandas DataFrame</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the time (GPS unit) to a datetime object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Times = np.zeros_like(time, object)\n",
    "gps_epoch = dt.datetime(1980, 1, 6)\n",
    "for j, t in enumerate(time):\n",
    "    Times[j] = (gps_epoch + dt.timedelta(seconds=time[j] - (35 - 19))).strftime(\"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_omi = pd.DataFrame(\n",
    "    {\n",
    "        \"latitude\": lats, \n",
    "        \"longitude\": lons, \n",
    "        alb_name: scatt_alb,\n",
    "        cloud_name: cloud_pres, \n",
    "        \"t\": Times, \n",
    "        \"traj_id\": traj_id\n",
    "    }\n",
    ")\n",
    "\n",
    "df_omi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_omi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_omi['longitude'] = df_omi['longitude']%360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: <font color=\"green\">Create the MovingPandas trajectory</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_omi = mpd.TrajectoryCollection(df_omi,\n",
    "                          traj_id_col=traj_id,\n",
    "                          x = \"longitude\", y=\"latitude\",\n",
    "                          t=\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_omi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: <font color=\"green\">Perform analyses and visualization</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wv3dOk6Frrqn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "introduction_geopandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
